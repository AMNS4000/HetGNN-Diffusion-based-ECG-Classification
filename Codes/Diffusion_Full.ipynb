{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/naman21266/Atul_ECG_Codes/Atul codes/codes/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 08:16:33.280223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-29 08:16:33.293350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-29 08:16:33.297315: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-29 08:16:33.306896: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 08:16:33.965071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, activations, regularizers, optimizers, losses, metrics, callbacks\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import scipy.signal as signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (19267, 1000, 12)\n",
      "Y_train : (19267, 5)\n",
      "X_test  : (2163, 1000, 12)\n",
      "Y_test  : (2163, 5)\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(path + 'x_train.npy')\n",
    "y_train = np.load(path + 'y_train.npy')\n",
    "x_test  = np.load(path + 'x_test.npy')\n",
    "y_test  = np.load(path + 'y_test.npy')\n",
    "\n",
    "# x_train = x_train.transpose(0, 2, 1)                # transpose working correctly\n",
    "# x_test  = x_test.transpose(0, 2, 1)\n",
    "\n",
    "# x_train = x_train.reshape(19267, 12, 1000, 1)       # Added another channel\n",
    "# x_test  = x_test.reshape(2163, 12, 1000, 1)\n",
    "\n",
    "print(\"X_train :\", x_train.shape)\n",
    "print(\"Y_train :\", y_train.shape)\n",
    "print(\"X_test  :\", x_test.shape)\n",
    "print(\"Y_test  :\", y_test.shape)\n",
    "print('Data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label Combination  Count\n",
      "0    (0, 0, 0, 1, 0)   8170\n",
      "1    (0, 0, 1, 0, 0)   2282\n",
      "2    (0, 0, 0, 0, 1)   2163\n",
      "4    (1, 0, 0, 0, 0)   1525\n",
      "7    (1, 0, 1, 0, 0)   1167\n",
      "10   (0, 1, 0, 0, 1)    710\n",
      "5    (0, 0, 1, 0, 1)    541\n",
      "3    (0, 1, 0, 0, 0)    480\n",
      "8    (1, 0, 0, 0, 1)    434\n",
      "13   (1, 0, 0, 1, 0)    362\n",
      "11   (0, 1, 1, 0, 1)    320\n",
      "6    (1, 1, 0, 0, 0)    273\n",
      "12   (1, 0, 1, 0, 1)    202\n",
      "15   (1, 1, 0, 0, 1)    186\n",
      "9    (0, 1, 1, 0, 0)    166\n",
      "14   (1, 1, 1, 0, 1)    142\n",
      "17   (1, 1, 1, 0, 0)    112\n",
      "16   (0, 0, 0, 1, 1)     24\n",
      "18   (1, 0, 0, 1, 1)      5\n",
      "19   (0, 1, 0, 1, 0)      2\n",
      "20   (1, 1, 1, 1, 0)      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label_cnt = {}\n",
    "for i in y_train:\n",
    "    key = tuple(i.tolist())\n",
    "    if key not in label_cnt:\n",
    "        label_cnt[key] = 1\n",
    "    else:\n",
    "        label_cnt[key] += 1\n",
    "\n",
    "df = pd.DataFrame(list(label_cnt.items()), columns=['Label Combination', 'Count'])\n",
    "df = df.sort_values(by='Count', ascending=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SelfAttention1D(nn.Module):\n",
    "    def __init__(self, channels, size):\n",
    "        super(SelfAttention1D, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.size = size\n",
    "        self.mha = nn.MultiheadAttention(channels, 4, batch_first=True)\n",
    "        self.ln = nn.LayerNorm([channels])\n",
    "        self.ff_self = nn.Sequential(\n",
    "            nn.LayerNorm([channels]),\n",
    "            nn.Linear(channels, channels),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(channels, channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.size, self.channels)\n",
    "        x_ln = self.ln(x)\n",
    "        attention_value, _ = self.mha(x_ln, x_ln, x_ln)\n",
    "        attention_value = attention_value + x\n",
    "        attention_value = self.ff_self(attention_value) + attention_value\n",
    "        return attention_value.view(-1, self.channels, self.size)\n",
    "\n",
    "\n",
    "class DoubleConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, residual=False):\n",
    "        super().__init__()\n",
    "        self.residual = residual\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, mid_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.GroupNorm(1, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.residual:\n",
    "            return F.gelu(x + self.double_conv(x))\n",
    "        else:\n",
    "            return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=1000):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool1d(2),\n",
    "            DoubleConv1D(in_channels, in_channels, residual=True),\n",
    "            DoubleConv1D(in_channels, out_channels),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.maxpool_conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None].repeat(1, 1, x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class Up1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, emb_dim=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"linear\", align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv1D(in_channels, in_channels, residual=True),\n",
    "            DoubleConv1D(in_channels, out_channels, in_channels // 2),\n",
    "        )\n",
    "\n",
    "        self.emb_layer = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(\n",
    "                emb_dim,\n",
    "                out_channels\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip_x, t):\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([skip_x, x], dim=1)\n",
    "        x = self.conv(x)\n",
    "        emb = self.emb_layer(t)[:, :, None].repeat(1, 1, x.shape[-1])\n",
    "        return x + emb\n",
    "\n",
    "\n",
    "class UNet1D(nn.Module):\n",
    "    def __init__(self, c_in=12, c_out=12, time_dim=1000, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.time_dim = time_dim\n",
    "        \n",
    "        self.inc = DoubleConv1D(c_in, 64)          # Input: (N, c_in=12, L=1000) -> Output: (N, 64, 1000)\n",
    "        self.down1 = Down1D(64, 128)               # Input: (N, 64, 1000) -> Output: (N, 128, 500)\n",
    "        self.sa1 = SelfAttention1D(128, 500)       # Input: (N, 128, 500) -> Output: (N, 128, 500)\n",
    "        \n",
    "        self.down2 = Down1D(128, 256)              # Input: (N, 128, 500) -> Output: (N, 256, 250)\n",
    "        self.sa2 = SelfAttention1D(256, 250)       # Input: (N, 256, 250) -> Output: (N, 256, 250)\n",
    "        \n",
    "        self.down3 = Down1D(256, 256)              # Input: (N, 256, 250) -> Output: (N, 256, 125)\n",
    "        self.sa3 = SelfAttention1D(256, 125)       # Input: (N, 256, 125) -> Output: (N, 256, 125)\n",
    "\n",
    "        self.bot1 = DoubleConv1D(256, 512)         # Input: (N, 256, 125) -> Output: (N, 512, 125)\n",
    "        self.bot2 = DoubleConv1D(512, 512)         # Input: (N, 512, 125) -> Output: (N, 512, 125)\n",
    "        self.bot3 = DoubleConv1D(512, 256)         # Input: (N, 512, 125) -> Output: (N, 256, 125)\n",
    "\n",
    "        self.up1 = Up1D(512, 128)                   # Input: (N, 256, 125) + (N, 512, 125) -> Output: (N, 128, 250)\n",
    "        self.sa4 = SelfAttention1D(128, 250)       # Input: (N, 128, 250) -> Output: (N, 128, 250)\n",
    "        \n",
    "        self.up2 = Up1D(256, 64)                    # Input: (N, 128, 250) + (N, 256, 250) -> Output: (N, 64, 500)\n",
    "        self.sa5 = SelfAttention1D(64, 500)        # Input: (N, 64, 500) -> Output: (N, 64, 500)\n",
    "        \n",
    "        self.up3 = Up1D(128, 64)                    # Input: (N, 64, 500) + (N, 64, 500) -> Output: (N, 64, 1000)\n",
    "        self.sa6 = SelfAttention1D(64, 1000)       # Input: (N, 64, 1000) -> Output: (N, 64, 1000)\n",
    "        \n",
    "        self.outc = nn.Conv1d(64, c_out, kernel_size=1)  # Input: (N, 64, 1000) -> Output: (N, c_out=12, 1000)\n",
    "\n",
    "    def pos_encoding(self, t, channels):\n",
    "        inv_freq = 1.0 / (\n",
    "            10000\n",
    "            ** (torch.arange(0, channels, 2, device=self.device).float() / channels)\n",
    "        )\n",
    "        pos_enc_a = torch.sin(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc_b = torch.cos(t.repeat(1, channels // 2) * inv_freq)\n",
    "        pos_enc = torch.cat([pos_enc_a, pos_enc_b], dim=-1)\n",
    "        return pos_enc\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t = t.unsqueeze(-1).type(torch.float)  # Input: (N, L=1000) -> Output: (N, 1)\n",
    "        t = self.pos_encoding(t, self.time_dim) # Output: (N, time_dim=1000)\n",
    "\n",
    "        x1 = self.inc(x)                         # Input: (N, c_in=12, L=1000) -> Output: (N, 64, 1000)\n",
    "        x2 = self.down1(x1, t)                  # Input: (N, 64, 1000) -> Output: (N, 128, 500)\n",
    "        x2 = self.sa1(x2)                       # Input: (N, 128, 500) -> Output: (N, 128, 500)\n",
    "        \n",
    "        x3 = self.down2(x2, t)                  # Input: (N, 128, 500) -> Output: (N, 256, 250)\n",
    "        x3 = self.sa2(x3)                       # Input: (N, 256, 250) -> Output: (N, 256, 250)\n",
    "\n",
    "        x4 = self.down3(x3, t)                  # Input: (N, 256, 250) -> Output: (N, 256, 125)\n",
    "        x4 = self.sa3(x4)                       # Input: (N, 256, 125) -> Output: (N, 256, 125)\n",
    "\n",
    "        x4 = self.bot1(x4)                      # Input: (N, 256, 125) -> Output: (N, 512, 125)\n",
    "        x4 = self.bot2(x4)                      # Input: (N, 512, 125) -> Output: (N, 512, 125)\n",
    "        x4 = self.bot3(x4)                      # Input: (N, 512, 125) -> Output: (N, 256, 125)\n",
    "\n",
    "        x = self.up1(x4, x3, t)                  # Input: (N, 256, 125) + (N, 512, 125) -> Output: (N, 128, 250)\n",
    "        x = self.sa4(x)                          # Input: (N, 128, 250) -> Output: (N, 128, 250)\n",
    "\n",
    "        x = self.up2(x, x2, t)                   # Input: (N, 128, 250) + (N, 256, 250) -> Output: (N, 64, 500)\n",
    "        x = self.sa5(x)                          # Input: (N, 64, 500) -> Output: (N, 64, 500)\n",
    "\n",
    "        x = self.up3(x, x1, t)                   # Input: (N, 64, 500) + (N, 64, 500) -> Output: (N, 64, 1000)\n",
    "        x = self.sa6(x)                          # Input: (N, 64, 1000) -> Output: (N, 64, 1000)\n",
    "\n",
    "        output = self.outc(x)                    # Input: (N, 64, 1000) -> Output: (N, c_out=12, 1000)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Assuming the UNet1D model is already defined as per your previous code\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(self, model, timesteps=1000, beta_start=1e-4, beta_end=0.02, device=\"cuda\"):\n",
    "        super(GaussianDiffusion, self).__init__()\n",
    "        self.model = model\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        \n",
    "        # Linearly spaced betas for noise schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps).to(self.device)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=self.device), self.alphas_cumprod[:-1]])\n",
    "\n",
    "        # Calculating the standard deviation for the forward process noise\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "\n",
    "    def q_sample(self, x_0, t, noise=None):\n",
    "        \"\"\"\n",
    "        Forward process: Sample from q(x_t | x_0) by adding Gaussian noise to the data.\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "        return (\n",
    "            self.sqrt_alphas_cumprod[t, None, None] * x_0 +\n",
    "            self.sqrt_one_minus_alphas_cumprod[t, None, None] * noise\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_0, t, noise=None):\n",
    "        \"\"\"\n",
    "        Training objective: Predict the noise that was added at timestep `t`.\n",
    "        \"\"\"\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_0)\n",
    "\n",
    "        x_t = self.q_sample(x_0, t, noise)\n",
    "        predicted_noise = self.model(x_t, t)\n",
    "\n",
    "        return F.mse_loss(predicted_noise, noise)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample(self, x, t, t_index):\n",
    "        \"\"\"\n",
    "        Reverse process: Sample from p(x_{t-1} | x_t)\n",
    "        \"\"\"\n",
    "        betas_t = self.betas[t].reshape(-1, 1, 1)\n",
    "        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t].reshape(-1, 1, 1)\n",
    "        sqrt_recip_alphas_t = torch.sqrt(1.0 / self.alphas[t]).reshape(-1, 1, 1)\n",
    "\n",
    "        # Predict noise\n",
    "        predicted_noise = self.model(x, t)\n",
    "\n",
    "        # Compute the mean of p(x_{t-1} | x_t)\n",
    "        model_mean = sqrt_recip_alphas_t * (x - betas_t * predicted_noise / sqrt_one_minus_alphas_cumprod_t)\n",
    "\n",
    "        if t_index == 0:\n",
    "            return model_mean\n",
    "        else:\n",
    "            noise = torch.randn_like(x)\n",
    "            return model_mean + torch.sqrt(self.betas[t]).reshape(-1, 1, 1) * noise\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def p_sample_loop(self, shape):\n",
    "        \"\"\"\n",
    "        Reverse process: Iterate over the timesteps to generate a sample from pure noise.\n",
    "        \"\"\"\n",
    "        b = shape[0]\n",
    "        img = torch.randn(shape, device=self.device)\n",
    "        imgs = []\n",
    "\n",
    "        for i in reversed(range(0, self.timesteps)):\n",
    "            img = self.p_sample(img, torch.full((b,), i, device=self.device, dtype=torch.long), i)\n",
    "            imgs.append(img.cpu().numpy())\n",
    "\n",
    "        return imgs\n",
    "\n",
    "    def sample(self, image_shape):\n",
    "        return self.p_sample_loop(image_shape)\n",
    "\n",
    "# Assuming UNet1D is already implemented from the previous message.\n",
    "# Initializing the diffusion model\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "unet_model = UNet1D(c_in=12, c_out=12, time_dim=1000, device=device).to(device)\n",
    "\n",
    "diffusion = GaussianDiffusion(unet_model, timesteps=1000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Batch [0/603] Loss: 1.5007\n",
      "Epoch [1/20] Batch [100/603] Loss: 0.2090\n",
      "Epoch [1/20] Batch [200/603] Loss: 0.1171\n",
      "Epoch [1/20] Batch [300/603] Loss: 0.1143\n",
      "Epoch [1/20] Batch [400/603] Loss: 0.1185\n",
      "Epoch [1/20] Batch [500/603] Loss: 0.0599\n",
      "Epoch [1/20] Batch [600/603] Loss: 0.0479\n",
      "Epoch [2/20] Batch [0/603] Loss: 0.0779\n",
      "Epoch [2/20] Batch [100/603] Loss: 0.0541\n",
      "Epoch [2/20] Batch [200/603] Loss: 0.0419\n",
      "Epoch [2/20] Batch [300/603] Loss: 0.0478\n",
      "Epoch [2/20] Batch [400/603] Loss: 0.0335\n",
      "Epoch [2/20] Batch [500/603] Loss: 0.0441\n",
      "Epoch [2/20] Batch [600/603] Loss: 0.0531\n",
      "Epoch [3/20] Batch [0/603] Loss: 0.0311\n",
      "Epoch [3/20] Batch [100/603] Loss: 0.0339\n",
      "Epoch [3/20] Batch [200/603] Loss: 0.0243\n",
      "Epoch [3/20] Batch [300/603] Loss: 0.0263\n",
      "Epoch [3/20] Batch [400/603] Loss: 0.0282\n",
      "Epoch [3/20] Batch [500/603] Loss: 0.0425\n",
      "Epoch [3/20] Batch [600/603] Loss: 0.0248\n",
      "Epoch [4/20] Batch [0/603] Loss: 0.0268\n",
      "Epoch [4/20] Batch [100/603] Loss: 0.0307\n",
      "Epoch [4/20] Batch [200/603] Loss: 0.0265\n",
      "Epoch [4/20] Batch [300/603] Loss: 0.0151\n",
      "Epoch [4/20] Batch [400/603] Loss: 0.0172\n",
      "Epoch [4/20] Batch [500/603] Loss: 0.0228\n",
      "Epoch [4/20] Batch [600/603] Loss: 0.0133\n",
      "Epoch [5/20] Batch [0/603] Loss: 0.0181\n",
      "Epoch [5/20] Batch [100/603] Loss: 0.0188\n",
      "Epoch [5/20] Batch [200/603] Loss: 0.0176\n",
      "Epoch [5/20] Batch [300/603] Loss: 0.0402\n",
      "Epoch [5/20] Batch [400/603] Loss: 0.0376\n",
      "Epoch [5/20] Batch [500/603] Loss: 0.0197\n",
      "Epoch [5/20] Batch [600/603] Loss: 0.0136\n",
      "Epoch [6/20] Batch [0/603] Loss: 0.0123\n",
      "Epoch [6/20] Batch [100/603] Loss: 0.0213\n",
      "Epoch [6/20] Batch [200/603] Loss: 0.0141\n",
      "Epoch [6/20] Batch [300/603] Loss: 0.0108\n",
      "Epoch [6/20] Batch [400/603] Loss: 0.0442\n",
      "Epoch [6/20] Batch [500/603] Loss: 0.0208\n",
      "Epoch [6/20] Batch [600/603] Loss: 0.0154\n",
      "Epoch [7/20] Batch [0/603] Loss: 0.0117\n",
      "Epoch [7/20] Batch [100/603] Loss: 0.0134\n",
      "Epoch [7/20] Batch [200/603] Loss: 0.0101\n",
      "Epoch [7/20] Batch [300/603] Loss: 0.0126\n",
      "Epoch [7/20] Batch [400/603] Loss: 0.0212\n",
      "Epoch [7/20] Batch [500/603] Loss: 0.0224\n",
      "Epoch [7/20] Batch [600/603] Loss: 0.0506\n",
      "Epoch [8/20] Batch [0/603] Loss: 0.0284\n",
      "Epoch [8/20] Batch [100/603] Loss: 0.0225\n",
      "Epoch [8/20] Batch [200/603] Loss: 0.0289\n",
      "Epoch [8/20] Batch [300/603] Loss: 0.0183\n",
      "Epoch [8/20] Batch [400/603] Loss: 0.0293\n",
      "Epoch [8/20] Batch [500/603] Loss: 0.0105\n",
      "Epoch [8/20] Batch [600/603] Loss: 0.0139\n",
      "Epoch [9/20] Batch [0/603] Loss: 0.0192\n",
      "Epoch [9/20] Batch [100/603] Loss: 0.0208\n",
      "Epoch [9/20] Batch [200/603] Loss: 0.0155\n",
      "Epoch [9/20] Batch [300/603] Loss: 0.0098\n",
      "Epoch [9/20] Batch [400/603] Loss: 0.0190\n",
      "Epoch [9/20] Batch [500/603] Loss: 0.0131\n",
      "Epoch [9/20] Batch [600/603] Loss: 0.0144\n",
      "Epoch [10/20] Batch [0/603] Loss: 0.0147\n",
      "Epoch [10/20] Batch [100/603] Loss: 0.0144\n",
      "Epoch [10/20] Batch [200/603] Loss: 0.0163\n",
      "Epoch [10/20] Batch [300/603] Loss: 0.0152\n",
      "Epoch [10/20] Batch [400/603] Loss: 0.0106\n",
      "Epoch [10/20] Batch [500/603] Loss: 0.0237\n",
      "Epoch [10/20] Batch [600/603] Loss: 0.0134\n",
      "Epoch [11/20] Batch [0/603] Loss: 0.0164\n",
      "Epoch [11/20] Batch [100/603] Loss: 0.0194\n",
      "Epoch [11/20] Batch [200/603] Loss: 0.0131\n",
      "Epoch [11/20] Batch [300/603] Loss: 0.0211\n",
      "Epoch [11/20] Batch [400/603] Loss: 0.0355\n",
      "Epoch [11/20] Batch [500/603] Loss: 0.0199\n",
      "Epoch [11/20] Batch [600/603] Loss: 0.0136\n",
      "Epoch [12/20] Batch [0/603] Loss: 0.0254\n",
      "Epoch [12/20] Batch [100/603] Loss: 0.0169\n",
      "Epoch [12/20] Batch [200/603] Loss: 0.0152\n",
      "Epoch [12/20] Batch [300/603] Loss: 0.0120\n",
      "Epoch [12/20] Batch [400/603] Loss: 0.0362\n",
      "Epoch [12/20] Batch [500/603] Loss: 0.0263\n",
      "Epoch [12/20] Batch [600/603] Loss: 0.0074\n",
      "Epoch [13/20] Batch [0/603] Loss: 0.0167\n",
      "Epoch [13/20] Batch [100/603] Loss: 0.0299\n",
      "Epoch [13/20] Batch [200/603] Loss: 0.0117\n",
      "Epoch [13/20] Batch [300/603] Loss: 0.0132\n",
      "Epoch [13/20] Batch [400/603] Loss: 0.0105\n",
      "Epoch [13/20] Batch [500/603] Loss: 0.0249\n",
      "Epoch [13/20] Batch [600/603] Loss: 0.0138\n",
      "Epoch [14/20] Batch [0/603] Loss: 0.0141\n",
      "Epoch [14/20] Batch [100/603] Loss: 0.0108\n",
      "Epoch [14/20] Batch [200/603] Loss: 0.0344\n",
      "Epoch [14/20] Batch [300/603] Loss: 0.0106\n",
      "Epoch [14/20] Batch [400/603] Loss: 0.0249\n",
      "Epoch [14/20] Batch [500/603] Loss: 0.0125\n",
      "Epoch [14/20] Batch [600/603] Loss: 0.0121\n",
      "Epoch [15/20] Batch [0/603] Loss: 0.0099\n",
      "Epoch [15/20] Batch [100/603] Loss: 0.0377\n",
      "Epoch [15/20] Batch [200/603] Loss: 0.0177\n",
      "Epoch [15/20] Batch [300/603] Loss: 0.0198\n",
      "Epoch [15/20] Batch [400/603] Loss: 0.0058\n",
      "Epoch [15/20] Batch [500/603] Loss: 0.0147\n",
      "Epoch [15/20] Batch [600/603] Loss: 0.0102\n",
      "Epoch [16/20] Batch [0/603] Loss: 0.0303\n",
      "Epoch [16/20] Batch [100/603] Loss: 0.0159\n",
      "Epoch [16/20] Batch [200/603] Loss: 0.0177\n",
      "Epoch [16/20] Batch [300/603] Loss: 0.0170\n",
      "Epoch [16/20] Batch [400/603] Loss: 0.0118\n",
      "Epoch [16/20] Batch [500/603] Loss: 0.0145\n",
      "Epoch [16/20] Batch [600/603] Loss: 0.0149\n",
      "Epoch [17/20] Batch [0/603] Loss: 0.0243\n",
      "Epoch [17/20] Batch [100/603] Loss: 0.0352\n",
      "Epoch [17/20] Batch [200/603] Loss: 0.0127\n",
      "Epoch [17/20] Batch [300/603] Loss: 0.0157\n",
      "Epoch [17/20] Batch [400/603] Loss: 0.0119\n",
      "Epoch [17/20] Batch [500/603] Loss: 0.0055\n",
      "Epoch [17/20] Batch [600/603] Loss: 0.0272\n",
      "Epoch [18/20] Batch [0/603] Loss: 0.0153\n",
      "Epoch [18/20] Batch [100/603] Loss: 0.0126\n",
      "Epoch [18/20] Batch [200/603] Loss: 0.0077\n",
      "Epoch [18/20] Batch [300/603] Loss: 0.0210\n",
      "Epoch [18/20] Batch [400/603] Loss: 0.0115\n",
      "Epoch [18/20] Batch [500/603] Loss: 0.0212\n",
      "Epoch [18/20] Batch [600/603] Loss: 0.0297\n",
      "Epoch [19/20] Batch [0/603] Loss: 0.0138\n",
      "Epoch [19/20] Batch [100/603] Loss: 0.0086\n",
      "Epoch [19/20] Batch [200/603] Loss: 0.0129\n",
      "Epoch [19/20] Batch [300/603] Loss: 0.0214\n",
      "Epoch [19/20] Batch [400/603] Loss: 0.0106\n",
      "Epoch [19/20] Batch [500/603] Loss: 0.0109\n",
      "Epoch [19/20] Batch [600/603] Loss: 0.0143\n",
      "Epoch [20/20] Batch [0/603] Loss: 0.0135\n",
      "Epoch [20/20] Batch [100/603] Loss: 0.0148\n",
      "Epoch [20/20] Batch [200/603] Loss: 0.0089\n",
      "Epoch [20/20] Batch [300/603] Loss: 0.0187\n",
      "Epoch [20/20] Batch [400/603] Loss: 0.0091\n",
      "Epoch [20/20] Batch [500/603] Loss: 0.0184\n",
      "Epoch [20/20] Batch [600/603] Loss: 0.0130\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you have the data in variables `train_data` (shape: (N, 12, 1000)) and `train_labels` (optional)\n",
    "training_data = x_train\n",
    "x_train_transposed = np.transpose(training_data, (0, 2, 1))\n",
    "x_train_tensor = torch.from_numpy(x_train_transposed).float()  # Convert to float if needed\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(diffusion.model.parameters(), lr=2e-4)\n",
    "\n",
    "def train_diffusion_model(diffusion, train_loader, epochs=10):\n",
    "    diffusion.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (x,) in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Random timestep t for each batch element\n",
    "            t = torch.randint(0, diffusion.timesteps, (x.shape[0],), device=device).long()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = diffusion.p_losses(x, t)\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] Batch [{batch_idx}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Train the model\n",
    "train_diffusion_model(diffusion, train_loader, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
